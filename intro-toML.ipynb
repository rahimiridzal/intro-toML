{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24ef739c",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning classification problem\n",
    "\n",
    "- Part 1: Data Preprocessing uisng NumPy only\n",
    "- Part 2: Import DecisionTree made from scratch using NumPy\n",
    "- Part 3: Training and Testing phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00584732",
   "metadata": {},
   "source": [
    " ## Part 1: Data Preprocessing using NumPy only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "adaf35a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6248d6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0001_01', 'Europa', 'False', ..., '0.0', 'Maham Ofracculy',\n",
       "        'False'],\n",
       "       ['0002_01', 'Earth', 'False', ..., '44.0', 'Juanna Vines', 'True'],\n",
       "       ['0003_01', 'Europa', 'False', ..., '49.0', 'Altark Susent',\n",
       "        'False'],\n",
       "       ...,\n",
       "       ['9279_01', 'Earth', 'False', ..., '0.0', 'Fayey Connon', 'True'],\n",
       "       ['9280_01', 'Europa', 'False', ..., '3235.0', 'Celeon Hontichre',\n",
       "        'False'],\n",
       "       ['9280_02', 'Europa', 'False', ..., '12.0', 'Propsh Hontichre',\n",
       "        'True']], dtype='<U18')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data from csv file\n",
    "data = np.genfromtxt(fname='data/data.csv', dtype=str, delimiter=',', skip_header=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9d7047de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8693, 14)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data shape to have a rough idea of the data we are dealing with\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "36b6959e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['False', 'True', 'False', ..., 'True', 'False', 'True'],\n",
       "      dtype='<U18')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store label column in y\n",
    "y = data[:,-1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0962ace6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 1., 0., 1.])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label encode y (True - 1, False - 0)\n",
    "y = np.where(y=='True', 1., 0.)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3b308e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0001_01' '0002_01' '0003_01' '0003_02' '0004_01']\n",
      "['Europa' 'Earth' 'Europa' 'Europa' 'Earth']\n",
      "['False' 'False' 'False' 'False' 'False']\n",
      "['B/0/P' 'F/0/S' 'A/0/S' 'A/0/S' 'F/1/S']\n",
      "['TRAPPIST-1e' 'TRAPPIST-1e' 'TRAPPIST-1e' 'TRAPPIST-1e' 'TRAPPIST-1e']\n",
      "['39.0' '24.0' '58.0' '33.0' '16.0']\n",
      "['False' 'False' 'True' 'False' 'False']\n",
      "['0.0' '109.0' '43.0' '0.0' '303.0']\n",
      "['0.0' '9.0' '3576.0' '1283.0' '70.0']\n",
      "['0.0' '25.0' '0.0' '371.0' '151.0']\n",
      "['0.0' '549.0' '6715.0' '3329.0' '565.0']\n",
      "['0.0' '44.0' '49.0' '193.0' '2.0']\n",
      "['Maham Ofracculy' 'Juanna Vines' 'Altark Susent' 'Solam Susent'\n",
      " 'Willy Santantines']\n",
      "['False' 'True' 'False' 'False' 'True']\n"
     ]
    }
   ],
   "source": [
    "# have a look at data from each column\n",
    "for j in range(data.shape[1]):\n",
    "    print(data[:5,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "24118679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0001_01' '0002_01' '0003_01' '0003_02' '0004_01']\n",
      "['Europa' 'Earth' 'Europa' 'Europa' 'Earth']\n",
      "['False' 'False' 'False' 'False' 'False']\n",
      "['B/0/P' 'F/0/S' 'A/0/S' 'A/0/S' 'F/1/S']\n",
      "['TRAPPIST-1e' 'TRAPPIST-1e' 'TRAPPIST-1e' 'TRAPPIST-1e' 'TRAPPIST-1e']\n",
      "['39.0' '24.0' '58.0' '33.0' '16.0']\n",
      "['False' 'False' 'True' 'False' 'False']\n",
      "['0.0' '109.0' '43.0' '0.0' '303.0']\n",
      "['0.0' '9.0' '3576.0' '1283.0' '70.0']\n",
      "['0.0' '25.0' '0.0' '371.0' '151.0']\n",
      "['0.0' '549.0' '6715.0' '3329.0' '565.0']\n",
      "['0.0' '44.0' '49.0' '193.0' '2.0']\n",
      "['Maham Ofracculy' 'Juanna Vines' 'Altark Susent' 'Solam Susent'\n",
      " 'Willy Santantines']\n"
     ]
    }
   ],
   "source": [
    "# drop the label column\n",
    "X = data[:,:-1]\n",
    "for j in range(X.shape[1]):\n",
    "    print(X[:5,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "64893454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col0 - unique: 8693, value: 0001_01\n",
      "col1 - unique: 4, value: Europa\n",
      "col2 - unique: 3, value: False\n",
      "col3 - unique: 6561, value: B/0/P\n",
      "col4 - unique: 4, value: TRAPPIST-1e\n",
      "col5 - unique: 81, value: 39.0\n",
      "col6 - unique: 3, value: False\n",
      "col7 - unique: 1274, value: 0.0\n",
      "col8 - unique: 1508, value: 0.0\n",
      "col9 - unique: 1116, value: 0.0\n",
      "col10 - unique: 1328, value: 0.0\n",
      "col11 - unique: 1307, value: 0.0\n",
      "col12 - unique: 8474, value: Maham Ofracculy\n"
     ]
    }
   ],
   "source": [
    "# some of the features are categorical variables\n",
    "# check which feature can be encoded and which feature we cannot\n",
    "for j in range(X.shape[1]):\n",
    "    x = X[:,j]\n",
    "    print(f\"col{j} - unique: {len(np.unique(x))}, value: {x[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "be4e7f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random: I found out that this result in number, so take note\n",
    "float('0001_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9e32d6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col0 - unique: 4, value: Europa\n",
      "col1 - unique: 3, value: False\n",
      "col2 - unique: 6561, value: B/0/P\n",
      "col3 - unique: 4, value: TRAPPIST-1e\n",
      "col4 - unique: 81, value: 39.0\n",
      "col5 - unique: 3, value: False\n",
      "col6 - unique: 1274, value: 0.0\n",
      "col7 - unique: 1508, value: 0.0\n",
      "col8 - unique: 1116, value: 0.0\n",
      "col9 - unique: 1328, value: 0.0\n",
      "col10 - unique: 1307, value: 0.0\n",
      "col11 - unique: 8474, value: Maham Ofracculy\n"
     ]
    }
   ],
   "source": [
    "# drop the Id feature because it is just an identifier\n",
    "X = X[:,1:]\n",
    "\n",
    "for j in range(X.shape[1]):\n",
    "    x = X[:,j]\n",
    "    print(f\"col{j} - unique: {len(np.unique(x))}, value: {x[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f0c4bef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['4', 'Europa'],\n",
       "       ['3', 'False'],\n",
       "       ['6561', 'B/0/P'],\n",
       "       ['4', 'TRAPPIST-1e'],\n",
       "       ['81', '39.0'],\n",
       "       ['3', 'False'],\n",
       "       ['1274', '0.0'],\n",
       "       ['1508', '0.0'],\n",
       "       ['1116', '0.0'],\n",
       "       ['1328', '0.0'],\n",
       "       ['1307', '0.0'],\n",
       "       ['8474', 'Maham Ofracculy']], dtype='<U32')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an array of unique, mode feature pairs\n",
    "uni_ftrs = np.empty((0,2))\n",
    "for j in range(X.shape[1]):\n",
    "    x = X[:,j]\n",
    "    uni_ftrs = np.append(uni_ftrs, np.reshape(np.array([len(np.unique(x)), x[0]]), (1,2)), axis=0)\n",
    "    # print(f\"col{j} - unique: {len(np.unique(x))}, value: {x[0]}\")\n",
    "uni_ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c6cc7732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2., 11.])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we do not care about numerical features for now\n",
    "# I will set the boundary to 10 (can be anything)\n",
    "# if unique >= 10 && feature is categorical, drop the feature\n",
    "# but first, get a list of feature indices that we want to drop\n",
    "\n",
    "col_idxs_todrop = np.empty((1,0))\n",
    "i = 0\n",
    "for uni, ftr in uni_ftrs:\n",
    "    try:\n",
    "        float(ftr)\n",
    "        pass\n",
    "    except ValueError:\n",
    "        if float(uni) >= 10:\n",
    "            col_idxs_todrop = np.append(col_idxs_todrop, np.array([i]))\n",
    "    i+=1\n",
    "    # print(i)\n",
    "col_idxs_todrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2604aad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8693, 10)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop those features\n",
    "X = np.delete(X, col_idxs_todrop.astype(int), axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5d409190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Europa' 'Earth' 'Europa' 'Europa' 'Earth']\n",
      "['False' 'False' 'False' 'False' 'False']\n",
      "['TRAPPIST-1e' 'TRAPPIST-1e' 'TRAPPIST-1e' 'TRAPPIST-1e' 'TRAPPIST-1e']\n",
      "['39.0' '24.0' '58.0' '33.0' '16.0']\n",
      "['False' 'False' 'True' 'False' 'False']\n",
      "['0.0' '109.0' '43.0' '0.0' '303.0']\n",
      "['0.0' '9.0' '3576.0' '1283.0' '70.0']\n",
      "['0.0' '25.0' '0.0' '371.0' '151.0']\n",
      "['0.0' '549.0' '6715.0' '3329.0' '565.0']\n",
      "['0.0' '44.0' '49.0' '193.0' '2.0']\n"
     ]
    }
   ],
   "source": [
    "#double check\n",
    "for j in range(X.shape[1]):\n",
    "    print(X[:5,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "56768445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['' 'Earth' 'Europa' 'Mars']\n",
      "['' 'False' 'True']\n",
      "['' '55 Cancri e' 'PSO J318.5-22' 'TRAPPIST-1e']\n",
      "['' '0.0' '1.0' '10.0' '11.0' '12.0' '13.0' '14.0' '15.0' '16.0' '17.0'\n",
      " '18.0' '19.0' '2.0' '20.0' '21.0' '22.0' '23.0' '24.0' '25.0' '26.0'\n",
      " '27.0' '28.0' '29.0' '3.0' '30.0' '31.0' '32.0' '33.0' '34.0' '35.0'\n",
      " '36.0' '37.0' '38.0' '39.0' '4.0' '40.0' '41.0' '42.0' '43.0' '44.0'\n",
      " '45.0' '46.0' '47.0' '48.0' '49.0' '5.0' '50.0' '51.0' '52.0' '53.0'\n",
      " '54.0' '55.0' '56.0' '57.0' '58.0' '59.0' '6.0' '60.0' '61.0' '62.0'\n",
      " '63.0' '64.0' '65.0' '66.0' '67.0' '68.0' '69.0' '7.0' '70.0' '71.0'\n",
      " '72.0' '73.0' '74.0' '75.0' '76.0' '77.0' '78.0' '79.0' '8.0' '9.0']\n",
      "['' 'False' 'True']\n",
      "['' '0.0' '1.0' ... '994.0' '995.0' '999.0']\n",
      "['' '0.0' '1.0' ... '9965.0' '997.0' '999.0']\n",
      "['' '0.0' '1.0' ... '99.0' '991.0' '994.0']\n",
      "['' '0.0' '1.0' ... '994.0' '995.0' '998.0']\n",
      "['' '0.0' '1.0' ... '994.0' '995.0' '998.0']\n"
     ]
    }
   ],
   "source": [
    "# now that we are left with features we want to use...\n",
    "# let us first check if there are any missing values (99% of the time there will be)\n",
    "for j in range(X.shape[1]):\n",
    "    print(np.unique(X[:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d11fb0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will handle the missing values using Imputation by Mode\n",
    "# basically replace the empty string (\"\") by the mode of respective feature\n",
    "# the function is defined as follow\n",
    "# note that sometimes the empty string (\"\") is the mode,\n",
    "# so a conditional statement is made to handle this case\n",
    "\n",
    "def mode_at_col(col):\n",
    "    vals, counts = np.unique(col, return_counts=True)\n",
    "    sorted_idxs = np.argsort(counts)\n",
    "    if vals[sorted_idxs[-1]] == '':\n",
    "        return vals[sorted_idxs[-2]]\n",
    "    else:\n",
    "        return vals[sorted_idxs[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9775391d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test mode_at_col with dummy data\n",
    "tmp = np.array(['1','','','2','2','1','','3','','2','4',''])\n",
    "mode_at_col(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "987baa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([False,  True]), array([8492,  201]))\n",
      "(array([False,  True]), array([8476,  217]))\n",
      "(array([False,  True]), array([8511,  182]))\n",
      "(array([False,  True]), array([8514,  179]))\n",
      "(array([False,  True]), array([8490,  203]))\n",
      "(array([False,  True]), array([8512,  181]))\n",
      "(array([False,  True]), array([8510,  183]))\n",
      "(array([False,  True]), array([8485,  208]))\n",
      "(array([False,  True]), array([8510,  183]))\n",
      "(array([False,  True]), array([8505,  188]))\n"
     ]
    }
   ],
   "source": [
    "# to have an insight why handling missing values is important, \n",
    "# see how many missing values we have\n",
    "for j in range(X.shape[1]):\n",
    "    X_j = X[:,j]\n",
    "    print(np.unique(X_j=='', return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fc0f1023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([False]), array([8693]))\n",
      "(array([False]), array([8693]))\n",
      "(array([False]), array([8693]))\n",
      "(array([False]), array([8693]))\n",
      "(array([False]), array([8693]))\n",
      "(array([False]), array([8693]))\n",
      "(array([False]), array([8693]))\n",
      "(array([False]), array([8693]))\n",
      "(array([False]), array([8693]))\n",
      "(array([False]), array([8693]))\n"
     ]
    }
   ],
   "source": [
    "# replace '' with the corresponding mode\n",
    "for j in range(X.shape[1]):\n",
    "    X_j = X[:,j]\n",
    "    X_j[X_j==''] = mode_at_col(X_j)\n",
    "    \n",
    "# now let us check again\n",
    "for j in range(X.shape[1]):\n",
    "    X_j = X[:,j]\n",
    "    print(np.unique(X_j=='', return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "69f3004c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nice! now we got rid of missing values\n",
    "np.unique(X=='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2a3a3267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we gonna have to one-hot encode categorical feature \n",
    "# one-hot encode function is defined as follows\n",
    "# it converts a column of categorical feature to 2d np array\n",
    "\n",
    "def one_hot_encode(col):\n",
    "    unique_vals = np.unique(col)\n",
    "    ohe = np.zeros((len(col), len(unique_vals)))\n",
    "    for i in range(len(col)):\n",
    "        ohe[i][unique_vals==col[i]]=1\n",
    "    return ohe\n",
    "\n",
    "# random: i got some weird stuff towards the end when using np.empty, \n",
    "# 0 becomes very small value that is not 0 for some reason (not sure yet why)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8355ea3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as usual, test it first\n",
    "tmp = np.array(['a','a','c','b','b'])\n",
    "tmp2 = one_hot_encode(tmp)\n",
    "tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2bf72070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nice, the function works!\n",
    "# now convert our string categorical column (meh) \n",
    "# to float 2d np array (yay)\n",
    "\n",
    "X_num = np.empty((X.shape[0],0))\n",
    "for j in range(X.shape[1]):\n",
    "    X_j = X[:,j]\n",
    "    try:\n",
    "        X_j = np.reshape(X_j.astype(float), (X_j.astype(float).shape[0],1))\n",
    "        X_num = np.append(X_num, X_j, axis=1)\n",
    "    except ValueError:\n",
    "        X_num = np.append(X_num, one_hot_encode(X_j), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "15902955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 1.]\n",
      "[1. 0. 1. 1. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1.]\n",
      "[39. 24. 58. 33. 16.]\n",
      "[1. 1. 0. 1. 1.]\n",
      "[0. 0. 1. 0. 0.]\n",
      "[  0. 109.  43.   0. 303.]\n",
      "[   0.    9. 3576. 1283.   70.]\n",
      "[  0.  25.   0. 371. 151.]\n",
      "[   0.  549. 6715. 3329.  565.]\n",
      "[  0.  44.  49. 193.   2.]\n"
     ]
    }
   ],
   "source": [
    "# double check\n",
    "for j in range(X_num.shape[1]):\n",
    "    print(X_num[:5,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a12de8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8693, 16)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and check the shape\n",
    "# think about why this is expected\n",
    "X_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "06990821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 1.]\n",
      "[1. 0. 1. 1. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1.]\n",
      "[39. 24. 58. 33. 16.]\n",
      "[1. 1. 0. 1. 1.]\n",
      "[0. 0. 1. 0. 0.]\n",
      "[  0. 109.  43.   0. 303.]\n",
      "[   0.    9. 3576. 1283.   70.]\n",
      "[  0.  25.   0. 371. 151.]\n",
      "[   0.  549. 6715. 3329.  565.]\n",
      "[  0.  44.  49. 193.   2.]\n"
     ]
    }
   ],
   "source": [
    "# I will use X from now on\n",
    "X = X_num\n",
    "for j in range(X.shape[1]):\n",
    "    print(X[:5,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e2b2d8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8693, 16), y shape: (8693,)\n"
     ]
    }
   ],
   "source": [
    "# now we have X and y, if we were to have a model now, we can split and train and test!\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "33fbadf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6954, 16)\n",
      "y_train shape: (6954,)\n",
      "X_test shape: (1739, 16)\n",
      "y_test shape: (1739,)\n"
     ]
    }
   ],
   "source": [
    "# now that we have our dataset in a good format, we can split it\n",
    "# into training and testing\n",
    "\n",
    "train_ratio = 0.8\n",
    "\n",
    "# calculate number of samples for training and testing sets\n",
    "n_samples = X.shape[0]\n",
    "train_size = int(train_ratio * n_samples)\n",
    "test_size = n_samples - train_size\n",
    "\n",
    "# shuffle the data\n",
    "idxs = np.random.permutation(n_samples)\n",
    "X = X[idxs]\n",
    "y = y[idxs]\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# print the shape of each set\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# End of Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e74776",
   "metadata": {},
   "source": [
    " ## Part 2: Import DecisionTree made from scratch using NumPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6a1ee3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how DecisionTree is implemented in decision_tree.py file\n",
    "\n",
    "from decision_tree import DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc7f805",
   "metadata": {},
   "source": [
    " ## Part 3: Training and Testing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4e1dd92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7883841288096607\n"
     ]
    }
   ],
   "source": [
    "# initialised the DecisionTree\n",
    "# set the maximum depth and minimum samples per node\n",
    "# max_depth = 8 gave the best performance\n",
    "\n",
    "dt = DecisionTree(max_depth=8, min_samples=10)\n",
    "\n",
    "# training\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# testing\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# accuracy function\n",
    "def acc(y_test, y_pred):\n",
    "    return np.sum(y_test == y_pred) / len(y_test)\n",
    "\n",
    "acc = acc(y_test, y_pred)\n",
    "print(f\"Accuracy : {acc}\")\n",
    "\n",
    "# End of Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b94a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
